<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
<title>Publications by Christian Rinderknecht</title>
</head>

<body>
<h1>cv_rinderknecht.bib</h1><a name="Rinderknecht_2013d"></a><pre>
@article{<a href="index.html#Rinderknecht_2013d">Rinderknecht_2013d</a>,
  author = {Nachum Dershowitz and Christian Rinderknecht},
  title = {{\textbf{The Average Height of Catalan Trees by Counting
                  Lattice Paths}}},
  journal = {Mathematics Magazine},
  year = 2015,
  month = jun,
  pdf = {<a href="../pub/mm2015.pdf">../pub/mm2015.pdf</a>},
  abstract = {The average height of Catalan trees (a.k.a. ordered
              trees) of a given size is a structural parameter
              important in the analysis of algorithms, as it measures
              the expected maximum cost of a search in a tree. This
              parameter was studied first with generating functions
              and complex variable theory, yielding an asymptotic
              approximation. Later on, real analysis was used
              instead of complex analysis. We reduce further the
              conceptual difficulty by replacing the generating
              functions with the enumeration of monotonous lattice
              paths, whose graphical representations make the
              derivation more intuitive.},
  volume = 88,
  number = 3,
  pages = {187--195},
  note = {18~pages (preprint, including supplement)}
}
</pre>

<a name="Rinderknecht_2014a"></a><pre>
@article{<a href="index.html#Rinderknecht_2014a">Rinderknecht_2014a</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{A Survey on Teaching and Learning Recursive
              Programming}}},
  journal = {Informatics in Education},
  year = 2014,
  month = apr,
  pdf = {<a href="../pub/ie2014.pdf">../pub/ie2014.pdf</a>},
  abstract = {We survey the literature about the teaching and
              learning of recursive programming. More precisely, we
              present the history of the advent of recursion in
              programming languages and its adoption by programmers,
              curricular approaches, textbooks, methodology,
              functional and imperative programming, control
              flow vs. data flow, the problem with base cases,
              induction in mathematics, analogies for recursion,
              games, visualizations and animations, multimedia
              environments, intelligent tutoring systems, visual
              programming, the \textsf{Logo} years, theoretical
              didactics, including constructivist and
              constructionist theories of learning, mental models,
              kinesthetic learning and syntonicity, etc. We append an
              extensive bibliography which was very carefully
              collated.},
  volume = 13,
  number = 1,
  pages = {87--119}
}
</pre>

<a name="Rinderknecht_2013b"></a><pre>
@inbook{<a href="index.html#Rinderknecht_2013b">Rinderknecht_2013b</a>,
  author = {Christian Rinderknecht},
  title = {{Communication Model in Distributed Cyber-Physical Systems}},
  chapter = {Model-based design and testing},
  publisher = {E\"otv\"os Lor\'and University},
  year = 2013,
  month = jun,
  note = {19~pages},
  pdf = {<a href="../pub/verif2013.pdf">../pub/verif2013.pdf</a>},
  abstract = {We survey existing tools and methods for the
                  simulation, testing and verification of concurrent
                  communicating systems, and their pertinence for
                  model-driven design and programming of
                  cyber-physical systems (also known as internet of
                  things). We also cover workflows and tests and
                  conclude with two proposals.}
}
</pre>

<a name="Rinderknecht_2013a"></a><pre>
@article{<a href="index.html#Rinderknecht_2013a">Rinderknecht_2013a</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{A Didactic Analysis of Merge Sort}}},
  journal = {Teaching Mathematics and Computer Science},
  month = oct,
  year = 2013,
  pdf = {<a href="../pub/tmcs2013.pdf">../pub/tmcs2013.pdf</a>},
  abstract = {Due to technical difficulties, educators teaching merge
              sort often avoid the analysis of the cost of merge sort
              in the general and average cases. Using basic discrete
              mathematics, elementary real analysis and mathematical
              induction, we propose a self-contained derivation of
              bounds $\alpha n \log(n) + \beta n + \gamma$ in all
              cases. Independent of any programming language or
              pseudo-code, supported by intuitive figures, it is
              suitable for informatics students with basic skills in
              mathematics. It is also a good exercise in showing that
              induction allows us to actually discover constants,
              instead of simply checking them a posteriori.},
  volume = 11,
  number = 2,
  pages = {195--210}
}
</pre>

<a name="Rinderknecht_2012b"></a><pre>
@book{<a href="index.html#Rinderknecht_2012b">Rinderknecht_2012b</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Conception et analyse des programmes purement
               fonctionnels}}},
  publisher = {College Publications},
  year = 2012,
  month = may,
  volume = 12,
  series = {Cahiers de logique et d'\'epist\'emologie},
  edition = {second},
  address = {United Kingdom},
  note = {528 pages, author's translation
               of~\cite{Rinderknecht_2012a}},
  pdf = {<a href="../pub/concept.pdf">../pub/concept.pdf</a>}
}
</pre>

<a name="Rinderknecht_2012a"></a><pre>
@book{<a href="index.html#Rinderknecht_2012a">Rinderknecht_2012a</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Design and Analysis of Purely Functional
               Programs}}},
  publisher = {College Publications},
  year = 2012,
  month = jan,
  volume = 15,
  series = {Texts in Computing},
  edition = {third},
  address = {United Kingdom},
  note = {650 pages},
  pdf = {<a href="../pub/design.pdf">../pub/design.pdf</a>},
  abstract = {This book addresses a priori different audiences whose
               common interest is functional programming.

               For undergraduate students, we offer a very
               progressive introduction to functional programming,
               with long developments about algorithms on stacks and
               some kinds of binary trees. We also study memory
               allocation through aliasing (dynamic data-sharing),
               the role of the control stack and the heap, automatic
               garbage collection (GC), the optimisation of tail
               calls and the total allocated memory. Program
               transformation into tail form, higher-order functions
               and continuation-passing style are advanced subjects
               presented in the context of the programming language
               Erlang. We give a technique for translating short
               functional programs to Java.

               For postgraduate students, each functional program is
               associated with the mathematical analysis of its
               minimum and maximum cost (efficiency), but also its
               average and amortised cost. The peculiarity of our
               approach is that we use elementary concepts
               (elementary calculus, induction, discrete mathematics)
               and we systematically seek explicit bounds in order to
               draw asymptotic equivalences. Furthermore, we cover in
               detail proofs of properties like correctness,
               termination and equivalence. An introduction to
               operational semantics is given in the context of the
               programming language OCaml, with a hint of type
               inference.

               For the professionals who do not know functional
               languages and who must learn how to program with the
               language XSLT, we propose an introduction which
               dovetails the part dedicated to undergraduate
               students. The reason of this unusual didactic choice
               lies on the observation that XSLT is rarely taught in
               college, therefore programmers who have not been
               exposed to functional programming face the two
               challenges of learning a new paradigm and use XML for
               programming: whereas the former puts forth recursion,
               the latter obscures it because of the inherent
               verbosity of XML. By learning first an abstract
               functional language, and then XML, we hope for a
               transfer of skills towards the design and
               implementation in XSLT without mediation.}
}
</pre>

<a name="Rinderknecht_2011"></a><pre>
@article{<a href="index.html#Rinderknecht_2011">Rinderknecht_2011</a>,
  author = {Christian Rinderknecht},
  title = {\textbf{A Didactic Analysis of Functional Queues}},
  journal = {Informatics in Education},
  year = 2011,
  volume = 10,
  number = 1,
  month = apr,
  pages = {65--72},
  pdf = {<a href="../pub/ie2011.pdf">../pub/ie2011.pdf</a>},
  keywords = {Didactics of informatics, analysis of algorithms,
               amortized analysis, aggregate analysis, functional
               queue, functional language, Dyck path, Dyck meander},
  abstract = {When first introduced to the analysis of algorithms,
               students are taught how to assess the best and worst
               cases, whereas the mean and amortized costs are
               considered advanced topics, usually saved for
               graduates. When presenting the latter, aggregate
               analysis is explained first because it is the most
               intuitive kind of amortized analysis, often
               involving enumerative combinatorics. We show how the
               aggregate analysis of functional queues can be
               carried out accurately and graphically, without
               combinatorics nor analytical tools like asymptotics,
               hence making it amenable to
               undergraduates. Furthermore, our presentation is
               independent of any programming language.}
}
</pre>

<a name="TasconRinderknechtKimKim_2010"></a><pre>
@inproceedings{<a href="index.html#TasconRinderknechtKimKim_2010">TasconRinderknechtKimKim_2010</a>,
  author = {Juan Diego Tasc\'on Vidarte and Christian
                  Rinderknecht and Jee-In Kim and HyungSeok Kim},
  title = {{\textbf{A Tangible Interface for Learning Recursion
                  and Functional Programming}}},
  booktitle = {Proceedings of the International Symposium on
                  Ubiquitous Virtual Reality},
  year = 2010,
  address = {Gwangju, Republic of Korea},
  month = jul,
  pdf = {<a href="../pub/isuvr2010.pdf">../pub/isuvr2010.pdf</a>},
  keywords = {functional programming, tangible user interface,
                  block world, augmented reality, software feedback.},
  abstract = {Recursion is a powerful programming
                  technique which is notoriously difficult to master,
                  especially in functional languages because they
                  prominently feature structural recursion as the main
                  control\--flow mechanism. We propose several
                  hypotheses to understand the issue and put some to
                  the test by designing an open\--source
                  interactive interface based on a tangible
                  block\--world with augmented reality and software
                  feedback. Stacks of blocks are used as an analogy
                  for the list data structure, which enables the
                  simplest form of structural recursion. After using
                  this application, students are expected to transfer
                  their training to directly write recursive programs
                  in sequential Erlang, a purely functional
                  language.}
}
</pre>

<a name="RinderknechtVolanschi_2010"></a><pre>
@article{<a href="index.html#RinderknechtVolanschi_2010">RinderknechtVolanschi_2010</a>,
  author = {Christian Rinderknecht and Nic Volanschi},
  title = {{\textbf{Theory and Practice of Unparsed Patterns
             for Metacompilation}}},
  journal = {Science of Computer Programming},
  month = mar,
  year = 2010,
  volume = 75,
  number = 3,
  pages = {85--105},
  pdf = {<a href="../pub/scp2010.pdf">../pub/scp2010.pdf</a>},
  keywords = {pattern matching, tree pattern, code checking,
              metacompilation, formal methods.},
  abstract = {Several software development tools support the matching
              of user-supplied patterns against the application
              source code, allowing the detection of invalid,
              risky, inefficient or forbidden constructs. When
              applied to compilers, this approach is called
              meta\-compilation. These patterns are traditionally
              parsed into tree patterns, i.e., fragments of
              abstract-syntax trees with meta\-variables, which
              are then matched against the abstract-syntax tree
              corresponding to the parsing of the source
              code. Parsing the patterns requires extending the
              grammar of the application programming language with
              meta\-variables, which can be difficult. Instead, we
              propose a novel matching algorithm which is
              independent of the programming language because the
              patterns are not parsed and, as such, are called
              unparsed patterns. It is more efficient than classic
              pattern matching and has the same capability. By
              giving up the possibility of static checks that
              parsed patterns usually enable, it can be integrated
              within any existing utility based on abstract-syntax
              trees at a low cost. We present an in-depth coverage
              of the practical and theoretical aspects of this new
              technique by describing a working minimal patch for
              the GNU \textsf{C} compiler, together with a small
              standalone prototype punned \textsf{Matchbox}, and
              by lying out a complete formalisation, including
              mathematical proofs of key algorithmic properties,
              like correctness and equivalence to the classic
              matching.}
}
</pre>

<a name="VolanschiRinderknecht_2008"></a><pre>
@inproceedings{<a href="index.html#VolanschiRinderknecht_2008">VolanschiRinderknecht_2008</a>,
  author = {Nic Volanschi and Christian Rinderknecht},
  title = {{\textbf{Unparsed Patterns: Easy User-extensibility of
              Program Manipulation Tools}}},
  booktitle = {Proceedings of the ACM SIGPLAN Symposium on Partial
               Evaluation and Semantics-based Program Manipulation
               (PEPM)},
  year = 2008,
  pages = {111--121},
  address = {San Francisco, USA},
  month = jan,
  pdf = {<a href="../pub/pepm2008.pdf">../pub/pepm2008.pdf</a>},
  keywords = {pattern matching, source code, unparsed patterns.},
  abstract = {Pattern matching in concrete syntax is very useful in
               program manipulation tools. In particular,
               user-defined extensions to such tools are written
               much easier using concrete syntax patterns. A few
               advanced frameworks for language development
               implement support for concrete syntax patterns, but
               mainstream frameworks used today still do not
               support them. This prevents most existing program
               manipulation tools from using concrete syntax
               matching, which in particular severely limits the
               writing of tool extensions to a few language
               experts. This paper argues that the major
               implementation obstacle to the pervasive use of
               concrete syntax patterns is the pattern parser. We
               propose an alternative approach based on ``unparsed
               patterns'', which are concrete syntax patterns that
               can be efficiently matched without being
               parsed. This lighter approach gives up static checks
               that parsed patterns usually do. In turn, it can be
               integrated within any existing parser-based software
               tool, almost for free. One possible consequence is
               enabling a widespread adoption of extensible program
               manipulation tools by the majority of programmers.
               Unparsed patterns can be used in any programing
               language, including multi-lingual environments. To
               demonstrate our approach, we implemented it both as
               a minimal patch for the gcc compiler, allowing to
               scan source code for user-defined patterns, and as a
               standalone prototype called matchbox.}
}
</pre>

<a name="Rinderknecht_2007"></a><pre>
@article{<a href="index.html#Rinderknecht_2007">Rinderknecht_2007</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Matching Pairwise Divergent Paths in
             XML Streams}}},
  journal = {Journal of Industrial Science and Technology},
  year = 2007,
  volume = 32,
  pages = {57--75},
  month = dec,
  pdf = {<a href="../pub/divergent2007.pdf">../pub/divergent2007.pdf</a>},
  keywords = {divergent paths, XML database, tree pattern matching,
              XPath.},
  abstract = {It is more and more common to query XML databases using
              the path language XPath or the more expressive
              language XQuery. A lot of attention has been devoted
              to solve efficiently the matching of streams of XML
              elements against XPath expressions, in particular
              when the relationship between the query nodes is
              either parent/child or ancestor/descendant. In the
              latter case, the semantics of XPath allows two
              descendants to be themselves in an
              ancestor/descendant relationship. In many cases,
              this leads to too general queries. We propose a
              novel primitive operation as a stricter
              interpretation of the ancestor/descendant relation
              that restricts the matches to the ending nodes of
              paths diverging from a common node in the data. We
              propose and compare several algorithms for answering
              this new type of query.}
}
</pre>

<a name="ITHET_2004"></a><pre>
@inproceedings{<a href="index.html#ITHET_2004">ITHET_2004</a>,
  author = {Patrick Duval and Agathe Merceron and Christian
               Rinderknecht and Michel Scholl},
  title = {{\textbf{LeVinQam: A Question Answering
               Mining Platform}}},
  booktitle = {Proceedings of the Fifth International Conference on
               Information Technology-based Higher Education and
               Training (ITHET)},
  year = 2004,
  address = {Istanbul, Turkey},
  month = jun,
  pdf = {<a href="../pub/ithet2004.pdf">../pub/ithet2004.pdf</a>},
  keywords = {data mining, e-learning, software platform.},
  abstract = {The development of Web technologies has accelerated
               the offer of (commercial) e-learning platforms. This
               paper is a first step toward the design and
               implementation of a platform called LeVinQam whose
               main functionalities are (a) the provision and
               management of a series of exercises and tests
               (authoring tools), (b) a personalized navigation
               through the existing collection of exercises and
               tests, taking into account the user profile (level
               of skills) and history, (c) the analysis of user
               answers, its storing into a database and its mining.
               As case studies we have chosen (1) the learning of
               SQL, the standard database query language, and (2)
               formal proofs for propositional logic, to validate
               the platform functionalities and the mining of
               answers.}
}
</pre>

<a name="SAM_2004"></a><pre>
@inproceedings{<a href="index.html#SAM_2004">SAM_2004</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Proving a Soundness Property of the Joint
               Design of ASN.1 and the Basic Encoding Rules}}},
  booktitle = {System Analysis and Modeling (SAM), Fourth
               International SDL and MSC Workshop},
  year = 2004,
  address = {Ottawa, Canada},
  month = jun,
  pages = {154--170},
  publisher = {LNCS, Springer Verlag},
  pdf = {<a href="../pub/sam2004.pdf">../pub/sam2004.pdf</a>},
  keywords = {Abstract Syntax Notation One, ASN.1, Basic Encoding
               Rules, BER, protocol, specification, vulnerabilities,
               formal methods.},
  abstract = {The Abstract Syntax Notation One (ASN.1) can be used to
               model types of values carried by signals in SDL or
               MSC but is also directly used by network protocol
               implementors. In the last few years, the press has
               reported several alleged vulnerabilities of ASN.1
               and the Basic Encoding Rules (BER) related to
               network protocols like SNMP and, more recently,
               OpenSSL. In reality it has been shown that the
               security issues (theoritically denial of service
               attacks) were due to low-quality and poorly-tested
               compiler implementations. We use some formal methods
               to go further. We review formally the design of the
               BER themselves and prove that, under some
               assumptions, it is flawless whatever the network
               protocol is and whatever the values to be
               transmitted are. More precisely, we start with a
               formal modeling of the BER which abstracts away
               low-level details but captures the design
               principles. Then we define a soundness property
               stating that the composition of encoding and
               decoding yields a value which is equivalent to the
               original. Finally we prove that this property holds
               for all values specified with ASN.1.}
}
</pre>

<a name="CJ_2003"></a><pre>
@article{<a href="index.html#CJ_2003">CJ_2003</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{An Algorithm for Validating ASN.1~(X.680)
              Specifications using Set Constraints}}},
  journal = {The Computer Journal},
  publisher = {Oxford University Press},
  year = 2003,
  month = jul,
  volume = 46,
  number = 4,
  pages = {401--420},
  pdf = {<a href="../pub/cj2003.pdf">../pub/cj2003.pdf</a>},
  keywords = {ASN.1, abstract syntax notation, validation,
               compilation, set constraints.},
  abstract = {\emph{Abstract Syntax Notation One} (ASN.1) is a
               standard language for defining data types whose
               values may be exchanged across a network between two
               communicating applications, independently from the
               possible heterogeneity of the peers. ASN.1 has been
               adopted by a wide range of applications, such as
               network management, secure email, mobile telephony,
               voice over IP etc. It offers a very involved
               subtyping paradigm consisting of constraints upon
               recursive types, which restrict their sets of values
               in a set-theoretic manner or in a structural
               way. Because of this great expressiveness, most
               ASN.1 compilers are not likely to fully check
               arbitrary combinations of subtyping constraints. We
               propose to fully validate the {X.680}
               specifications, i.e., the main part of ASN.1, by
               means of an algorithm which relies on the set
               constraints theory. Set constraints are inclusions
               between expressions interpreted over the domain of
               sets of trees which may be recursively defined. We
               define a system of constraints which can model all
               the specifications, we provide a complete collecting
               algorithm which extracts such constraints from a
               given specification, and, finally, we give a solving
               procedure which relies upon an algorithm of Aiken
               and Wimmers. As a result, either the constraints
               have no solutions (and the specification must be
               rejected), or the value sets can be finitely
               represented. It is straightforward to determine
               whether these value sets are empty; if they are
               empty then the specification is rejected. This
               article addresses both the network tool implementors
               and the theorist audience.}
}
</pre>

<a name="ASWN_2001"></a><pre>
@inproceedings{<a href="index.html#ASWN_2001">ASWN_2001</a>,
  author = {Ana Cavalli et al.},
  title = {{\textbf{PLATONIS: A Platform for Validation and
              Experimentation of Multi-protocols and Multi-services}}},
  booktitle = {Applications and Services in Wireless Networks (ASWN)},
  address = {\'Evry, France},
  year = 2001,
  month = jul,
  pages = {217--229},
  pdf = {<a href="../pub/asw2001.pdf">../pub/asw2001.pdf</a>},
  keywords = {Mobile network and services, WAP,
               interoperability test, conformance test.},
  abstract = {Advance in network technology leads to the design of
               new protocols and services. In order to assure
               successful communication among those new products,
               testing and validation activities for conformance
               and interoperability play an important role in the
               development and deployment of them. In this paper,
               we introduce the PLATONIS platform, a platform for
               validating and experimentation of new protocols and
               services.  It will, in particular, focus on WAP
               protocols and services but is expected to be general
               enough to be used for other protocols and services
               such as those of GPRS, UMTS, and wired networks.}
}
</pre>

<a name="ISCC_2001"></a><pre>
@inproceedings{<a href="index.html#ISCC_2001">ISCC_2001</a>,
  author = {Ana Cavalli and Bruno Defude and Christian
               Rinderknecht and Fatiha Za\"{\i}di},
  title = {{\textbf{A Service-component Testing Method and a
               suitable CORBA Architecture}}},
  booktitle = {Proceedings of the Sixth IEEE Symposium on Computers
               and Communications (ISCC)},
  year = 2001,
  address = {Hammamet, Tunisia},
  month = jul,
  pages = {655--666},
  pdf = {<a href="../pub/iscc2001.pdf">../pub/iscc2001.pdf</a>},
  keywords = {component testing, test generation, test architecture,
               CORBA.},
  abstract = {This paper presents a method for service-component
               testing and a suitable CORBA test architecture. This
               test environment allows the service validation from
               its components and is a close step towards the
               execution of the obtained tests on a CORBA
               environment. Two aspects are relevant: the test of
               components and the test architecture. The testing
               method for components is new: it is based on the
               generation of partial graphs and avoids the
               combinatorial explosion of number of states of the
               global system. The test architecture on a CORBA
               platform is also new, since there are few works on
               testing based on these environments. As an
               application we present a case study on a real
               conference call service.}
}
</pre>

<a name="CFIP_2000"></a><pre>
@inproceedings{<a href="index.html#CFIP_2000">CFIP_2000</a>,
  author = {Ana Cavalli and Bruno Defude and Christian Rinderknecht
               and Fatiha Za\"{\i}di},
  title = {{\textbf{Test de composants de service et ex\'ecution de
               tests sur une plate-forme CORBA}}},
  pages = {363--378},
  booktitle = {Actes de la Conf\'erence Francophone en Ing\'enierie
               des Protocoles},
  year = 2000,
  publisher = {Hermes},
  address = {Toulouse, France},
  month = oct,
  pdf = {<a href="../pub/cfip2000.pdf">../pub/cfip2000.pdf</a>},
  keywords = {Component testing, embedded testing, test generation,
               test execution, CORBA.},
  abstract = {In this article we present a testing platform and its
               application to an audioconference service. This
               software platform allows to validate a service based
               on its components and it runs the automatically
               derived tests on CORBA. The focus is on two aspects:
               the test of embedded components and the execution of
               these tests on a CORBA middleware. The method
               employed for deriving the tests of the embedded
               components is new. It is based on the partial
               generation of reachability graphs and avoids the
               combinatorial explosion of the explored state
               space. The test running on CORBA is also new, to our
               knowledge, since there are few works about the
               validation and execution of tests on this environment.}
}
</pre>

<a name="JDIR_1999"></a><pre>
@inproceedings{<a href="index.html#JDIR_1999">JDIR_1999</a>,
  author = {Ana Cavalli and David Lee and Christian Rinderknecht
                  and Fatiha Za\"{\i}di},
  title = {{\textbf{Hit-or-Jump: Un algorithme pour le test
                 imbriqu\'e avec des applications aux services R.I.}}},
  booktitle = {Actes de la troisi\`eme \'edition des Journ\'ees
                  Doctorales Informatique et R\'eseaux},
  year = 1999,
  month = nov,
  pdf = {<a href="../pub/jdir1999.pdf">../pub/jdir1999.pdf</a>},
  organization = {Institut National des T\'el\'ecommunications,
                  \'Evry, France}
}
</pre>

<a name="FORTE_1999"></a><pre>
@inproceedings{<a href="index.html#FORTE_1999">FORTE_1999</a>,
  author = {Ana Cavalli and David Lee and Christian Rinderknecht
               and Fatiha Za\"{\i}di},
  title = {{\textbf{Hit-or-Jump: An Algorithm for Embedded
               Testing with Applications to IN Services}}},
  pages = {41--56},
  booktitle = {Formal Methods for Protocol Engineering and
               Distributed Systems (FORTE)},
  year = 1999,
  address = {Beijing, China},
  month = oct,
  pdf = {<a href="../pub/forte1999.pdf">../pub/forte1999.pdf</a>},
  keywords = {conformance testing, embedded testing, communicating
               extended finite state machines, IN.},
  abstract = {This paper presents a new algorithm, called
               Hit-or-jump, for embedded testing of components of
               communication systems that can be modeled by
               communicating extended finite state machines. It
               constructs test sequences efficiently with a high
               fault coverage. It does not have state space
               explosion, as is often encountered in exhaustive
               search, and it quickly covers the system components
               under test without being `trapped', as is experienced
               by random walks. Furthermore, it is a generalization
               and unification of both exhaustive search and random
               walks; both are special cases of Hit-or-Jump.  The
               algorithm has been implemented and applied to embedded
               testing of telephone services in an Intelligent
               Network (IN) architecture, including the Basic Call
               Service and five supplementary services.}
}
</pre>

<a name="PhD_1998"></a><pre>
@phdthesis{<a href="index.html#PhD_1998">PhD_1998</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Une formalisation d'ASN.1 ---~Application
              d'une m\'ethode formelle \`a un langage de
              sp\'ecification t\'el\'ecom}}},
  school = {Universit\'e Pierre et Marie Curie (Paris 6)},
  year = 1998,
  month = dec,
  pdf = {<a href="../pub/these.pdf">../pub/these.pdf</a>},
  keywords = {ASN.1, Basic Encoding Rules, BER, formal methods,
              correctness, formal proof, ISO protocols.},
  abstract = {ASN.1 is a joint standard of ISO and ITU allowing the
              description of the types of the data possibly
              exchanged between two remote applications, even if
              these applications have been built on different
              programming languages and are running on
              heterogeneous software and hardware
              environments. The great expressiveness of ASN.1, the
              lack of a formal reference model has lead to several
              non- conformant compilers. Our thesis is that the
              usage of formal methods which are usually employed
              in the field of theoretical computer science, brings
              to the fore the grey areas of the standard, suggests
              how to fix the problems in accordance with the
              current industrial practices, and allows to make
              some formal proofs of correctness, which is an
              added-value for any company wondering about ASN.1
              technologies.}
}
</pre>

<a name="MaunyRinderknecht_1997"></a><pre>
@misc{<a href="index.html#MaunyRinderknecht_1997">MaunyRinderknecht_1997</a>,
  author = {Michel Mauny and Christian Rinderknecht},
  title = {{Position paper about the ASN.1 Formal Model}},
  note = {ISO working document},
  year = 1997
}
</pre>

<a name="INRIA_1995"></a><pre>
@techreport{<a href="index.html#INRIA_1995">INRIA_1995</a>,
  author = {Christian Rinderknecht},
  title = {{\textbf{Une analyse syntaxique d'{ASN.1:1990} en
                Caml Light}}},
  institution = {INRIA},
  year = 1995,
  number = 171,
  month = apr,
  pdf = {<a href="../pub/RT171.pdf">../pub/RT171.pdf</a>},
  keywords = {ASN.1, specification language, ISO protocols, Caml,
                 ML, functional languages, syntactic analysis,
                 parsing.},
  abstract = {ASN.1 is a specification language for network
                 protocols, standardized by the ISO and frequently
                 used in telecommunications. It allows the modular
                 description of the types and values that may be
                 exchanged between two remote applications, built and
                 running on heterogeneous environments. The ambiguity
                 of the ASN.1 grammar, in its 1990 version, led the
                 compiler designers to compromise with the normative
                 document. We show in this work how to transform the
                 grammar into an LL(1) equivalent one. A parser has
                 been implemented in Caml Light, a typed functional
                 language of the ML family. It offers the security of
                 strong static type inference and the expressivity of
                 higher-order functions, which are useful features to
                 build abstract syntax trees and handle ASN.1
                 macro-processing on the fly, leading to a notable
                 \emph{one-pass parser}. A general method for writing
                 parsers in Caml Light is also given, as a side
                 effect of this research, and the fully commented
                 code of the parser is also presented.},
  note = {English at \url{http://crinderknecht.free.fr/pub/TR171-eng.pdf}}
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.99.</em></p>
</body>
</html>
